{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca19c454",
   "metadata": {},
   "source": [
    "We want to load the .npz files for each training dataset / test dataset / phenotype combination. Then, we will aggregate across all datasets/phenotypes and save several different .csv files:\n",
    "\n",
    "- within.csv\n",
    "- within_grouped.csv\n",
    "- performance_grouped.csv\n",
    "- power_grouped.csv\n",
    "- effect_size.csv\n",
    "- full_test.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a59911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mjr239/anaconda3/envs/repro/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822ac72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>pheno</th>\n",
       "      <th>n</th>\n",
       "      <th>n_heldout</th>\n",
       "      <th>n_train</th>\n",
       "      <th>percent_heldout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abcd</td>\n",
       "      <td>age</td>\n",
       "      <td>7996</td>\n",
       "      <td>1600</td>\n",
       "      <td>6396</td>\n",
       "      <td>0.200100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hbn</td>\n",
       "      <td>age</td>\n",
       "      <td>1201</td>\n",
       "      <td>200</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.166528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hcpd</td>\n",
       "      <td>age</td>\n",
       "      <td>599</td>\n",
       "      <td>100</td>\n",
       "      <td>499</td>\n",
       "      <td>0.166945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pnc</td>\n",
       "      <td>age</td>\n",
       "      <td>1179</td>\n",
       "      <td>200</td>\n",
       "      <td>979</td>\n",
       "      <td>0.169635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abcd</td>\n",
       "      <td>mr</td>\n",
       "      <td>7846</td>\n",
       "      <td>1600</td>\n",
       "      <td>6246</td>\n",
       "      <td>0.203926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset pheno     n  n_heldout  n_train  percent_heldout\n",
       "0    abcd   age  7996       1600     6396         0.200100\n",
       "1     hbn   age  1201        200     1001         0.166528\n",
       "2    hcpd   age   599        100      499         0.166945\n",
       "3     pnc   age  1179        200      979         0.169635\n",
       "4    abcd    mr  7846       1600     6246         0.203926"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Select dataset type as one of the following options:\n",
    "\n",
    "main: primary results for developmental functional connectivity analysis (HBN, ABCD, HCPD, PNC)\n",
    "\n",
    "dev_sc: results using developmental structural connectivity (HBN, HCPD, QTAB)\n",
    "\n",
    "adult_fc: results using adult functional connectivity (CHCP, HCP)\n",
    "\n",
    "adult_sc: results using adult structural connectivity (CHCP, HCP)\n",
    "\n",
    "data_amount_train: results varying the scan length of the training data\n",
    "\n",
    "data_amount_test: results varying the scan length of the external/test data\n",
    "'''\n",
    "\n",
    "dataset_type = 'main'\n",
    "\n",
    "# set save path\n",
    "if dataset_type=='dev_sc':\n",
    "    save_path = '/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/results/dev_sc/processed_csv_files' \n",
    "    load_path = '/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/results/dev_sc/' \n",
    "\n",
    "    # load in sample size information\n",
    "    df_sample_size = pd.read_csv('/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/sample_size/dev_sc_pheno_dataset_sample_size.csv')\n",
    "    pheno_all = list( df_sample_size.pheno.unique() )\n",
    "\n",
    "elif dataset_type=='adult_fc':\n",
    "    save_path = '/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/results/adult/adult_fc_processed_csv_files' \n",
    "    load_path = '/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/results/adult/' \n",
    "\n",
    "    # load in sample size information\n",
    "    df_sample_size = pd.read_csv('/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/sample_size/adult_pheno_dataset_sample_size.csv')\n",
    "    df_sample_size = df_sample_size[df_sample_size.dataset.isin(['chcp', 'hcp'])].reset_index(drop=True)\n",
    "    pheno_all = list( df_sample_size.pheno.unique() )\n",
    "    \n",
    "elif dataset_type=='adult_sc':\n",
    "    save_path = '/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/results/adult/adult_sc_processed_csv_files' \n",
    "    load_path = '/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/results/adult/' \n",
    "    \n",
    "    # load in sample size information\n",
    "    df_sample_size = pd.read_csv('/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/sample_size/adult_pheno_dataset_sample_size.csv')\n",
    "    df_sample_size = df_sample_size[df_sample_size.dataset.isin(['chcp_sc', 'hcp_sc'])].reset_index(drop=True)\n",
    "\n",
    "    pheno_all = list( df_sample_size.pheno.unique() )\n",
    "elif dataset_type=='data_amount_train':\n",
    "    save_path = '/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/results/data_amount/data_amount_train_processed_csv_files' \n",
    "    load_path = '/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/results/data_amount/' \n",
    "    \n",
    "    # load in sample size information\n",
    "    df_sample_size = pd.read_csv('/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/sample_size/data_amount_pheno_dataset_sample_size.csv')\n",
    "    \n",
    "    pheno_all = [p for p in list( df_sample_size.pheno.unique() ) if (p!='mr_scaled' and p!='wm_corrected')]  # remove scaled metrics\n",
    "\n",
    "elif dataset_type=='data_amount_test':\n",
    "    save_path = '/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/results/data_amount/data_amount_test_processed_csv_files' \n",
    "    load_path = '/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/results/data_amount/' \n",
    "    \n",
    "    # load in sample size information\n",
    "    df_sample_size = pd.read_csv('/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/sample_size/pheno_dataset_sample_size.csv')\n",
    "    df_sample_size = df_sample_size[df_sample_size.dataset!='abcd'].reset_index(drop=True)\n",
    "    \n",
    "    pheno_all = [p for p in list( df_sample_size.pheno.unique() ) if (p!='mr_scaled' and p!='wm_corrected')]  # remove scaled metrics\n",
    "elif dataset_type=='main':\n",
    "    save_path = '/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/results/processed_csv_files'\n",
    "    load_path = '/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/results/'\n",
    "\n",
    "    # load in sample size information\n",
    "    df_sample_size = pd.read_csv('/data_dustin/store3/training/matt/repro_data_final/updates_nat_hum_behav/sample_size/pheno_dataset_sample_size.csv')\n",
    "    pheno_all = list( df_sample_size.pheno.unique() )\n",
    "    \n",
    "df_sample_size.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "157dc347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get held-out sizes for each dataset\n",
    "heldout_size_dict = dict({'abcd':1600, 'hbn':200, 'pnc':200, 'hcpd':100,\n",
    "                         'hbn_sc':500, 'hcpd_sc':100, 'qtab_sc':100,\n",
    "                         'hcp':200, 'hcp_sc':200, 'chcp':75, 'chcp_sc':75,\n",
    "                         'abcd_1_scans':800, 'abcd_2_scans':800, 'abcd_3_scans':800, 'abcd_4_scans':800})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1160d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define various functions\n",
    "\n",
    "def r_to_p(r, n):\n",
    "    '''\n",
    "    for one-sided positive test only\n",
    "    '''\n",
    "    t = r / np.sqrt((1-r**2)/ (n-2) )\n",
    "    p = stats.t.sf(t, df=n-2)   # positive only\n",
    "    \n",
    "    return p\n",
    "\n",
    "def p_to_r(p, n):\n",
    "    '''\n",
    "    for one-sided positive test only, undoes r_to_p\n",
    "    '''\n",
    "    t_inv = stats.t.isf(p, df=n-2)\n",
    "    r = np.sqrt(t_inv**2 / ( (n-2) * (1+t_inv**2/(n-2)) ))\n",
    "    return r \n",
    "\n",
    "# functions for finding quantiles from dataframes\n",
    "def qlower(x):\n",
    "    return x.quantile(0.025)\n",
    "def qupper(x):\n",
    "    return x.quantile(0.975)\n",
    "\n",
    "\n",
    "def power_curve_1t(r, N):\n",
    "    '''\n",
    "    power curve for correlation (one-tailed, testing >0)\n",
    "    '''\n",
    "    # MATLAB code: power1 = 1 - cdf('Normal',1.96,atanh(r_true)*sqrt(N-3), 1);  % one tail\n",
    "    N = np.array(N)  # allows for multiple N\n",
    "    return 1-norm.cdf(x=1.645, loc=np.arctanh(r)*np.sqrt(N-3), scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a46ec",
   "metadata": {},
   "source": [
    "# Process .npz files and save as .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08543d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 6/6 [30:45<00:00, 307.56s/it]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell takes loads the .npz files for each training dataset / test dataset / phenotype combination\n",
    "Then, it saves a .csv file for each .npz file\n",
    "'''\n",
    "\n",
    "# number of permutations we used\n",
    "num_perm_external = 500\n",
    "num_perm_internal = 10000\n",
    "\n",
    "# loop over all possible phenotypes\n",
    "for pheno in tqdm(pheno_all):\n",
    "    \n",
    "    # get all datasets\n",
    "    if dataset_type!='main':\n",
    "        all_datasets = list(df_sample_size.dataset.unique())\n",
    "    else:\n",
    "        # get relevant datasets for each phenotype\n",
    "        if (pheno=='mr_scaled') or (pheno=='wm_corrected'):  # no scaled phenotypes for PNC\n",
    "            all_datasets = ['abcd', 'hbn', 'hcpd']\n",
    "        else:\n",
    "            all_datasets = ['abcd', 'hbn', 'hcpd', 'pnc']\n",
    "\n",
    "    # loop over all training datasets\n",
    "    for train_dataset in all_datasets:\n",
    "        \n",
    "        # get corresponding test datasets and loop over\n",
    "        if 'data_amount' not in dataset_type:\n",
    "            all_test_datasets = [t for t in all_datasets if t!=train_dataset]\n",
    "        elif dataset_type=='data_amount_train':\n",
    "            all_test_datasets = ['hbn', 'hcpd', 'pnc']\n",
    "        elif dataset_type=='data_amount_test':\n",
    "            all_test_datasets = ['abcd_1_scans', 'abcd_2_scans', 'abcd_3_scans', 'abcd_4_scans']\n",
    "            \n",
    "        # loop over all test datasets\n",
    "        for within_idx, test_dataset in enumerate(all_test_datasets):\n",
    "\n",
    "            #################### loading and make initial dataframe ####################\n",
    "            dat = np.load(os.path.join(load_path,\n",
    "                                       'across_aggregated/results_train_'+ train_dataset + '_test_' +\\\n",
    "                          test_dataset + '_pheno_' + pheno + '.npz') )\n",
    "            df_results = pd.DataFrame()\n",
    "            for k in dat.files:  # read in all saved variables into dataframe columns\n",
    "                df_results[k] = dat[k]\n",
    "\n",
    "\n",
    "            #################### add new columns ####################\n",
    "            # first get heldout size for within dataset internal validation\n",
    "            df_results['heldout_size'] = np.array([heldout_size_dict[d] for d in list(df_results.train_dataset)])\n",
    "\n",
    "            # now get p values for internal and external validation\n",
    "            df_results['p_internal'] = r_to_p(np.array(df_results.r_internal), np.array(df_results.heldout_size))\n",
    "            df_results['p_external'] = r_to_p(np.array(df_results.r_external), np.array(df_results.num_test))\n",
    "\n",
    "            # add column for combination of dataset and phenotype\n",
    "            df_results['test_dataset_pheno'] = df_results['test_dataset'] + '_' + df_results['pheno']\n",
    "            df_results['train_dataset_pheno'] = df_results['train_dataset'] + '_' + df_results['pheno']\n",
    "\n",
    "            # add in max training/test sizes\n",
    "            df_results['ntest_max'] = df_results.num_test.max()\n",
    "            df_results['ntrain_max'] = df_results.num_train.max()\n",
    "\n",
    "            # adjust permutation test p values by 1/num_perm\n",
    "            df_results['p_perm_mae_internal'] = df_results['p_perm_mae_internal'].apply(lambda x: 1/num_perm_internal+x)\n",
    "            df_results['p_perm_mae_external'] = df_results['p_perm_mae_external'].apply(lambda x: 1/num_perm_external+x)\n",
    "            df_results['p_perm_r_internal'] = df_results['p_perm_r_internal'].apply(lambda x: 1/num_perm_internal+x)\n",
    "            df_results['p_perm_r_external'] = df_results['p_perm_r_external'].apply(lambda x: 1/num_perm_external+x)\n",
    "            \n",
    "            # add ground truth performance\n",
    "            df_results['train_test_pheno'] = df_results['train_dataset'] + '_' + df_results['test_dataset'] + '_' + df_results['pheno']\n",
    "            df_results['r_gt'] = df_results[ (df_results.num_train==df_results.num_train.max()) &\n",
    "                                            (df_results.num_test==df_results.num_test.max()) ].r_external.median()\n",
    "            df_results['p_gt'] = df_results[ (df_results.num_train==df_results.num_train.max()) &\n",
    "                                            (df_results.num_test==df_results.num_test.max()) ].p_external.median()\n",
    "            df_results['mae_gt'] = df_results[ (df_results.num_train==df_results.num_train.max()) &\n",
    "                                            (df_results.num_test==df_results.num_test.max()) ].mae_external.median()\n",
    "            df_results['p_mae_gt'] = df_results[ (df_results.num_train==df_results.num_train.max()) &\n",
    "                                            (df_results.num_test==df_results.num_test.max()) ].p_perm_mae_external.median()\n",
    "            df_results['p_mae_gt_internal'] = df_results[ (df_results.num_train==df_results.num_train.max()) ].p_perm_mae_internal.median()\n",
    "            \n",
    "            # add in columns for significance\n",
    "            pthresh = 0.05\n",
    "            df_results['sig_internal'] = 1.0*(df_results['p_internal']<pthresh)\n",
    "            df_results['sig_external'] = 1.0*(df_results['p_external']<pthresh)\n",
    "            df_results['sig_gt'] = 1.0*(df_results['p_gt']<pthresh)\n",
    "            df_results['sig_internal_mae'] = 1.0*(df_results['p_perm_mae_internal']<pthresh)\n",
    "            df_results['sig_external_mae'] = 1.0*(df_results['p_perm_mae_external']<pthresh)\n",
    "            df_results['sig_gt_mae'] = 1.0*(df_results['p_mae_gt']<pthresh)\n",
    "                    \n",
    "            if within_idx==0:  # only want within dataset on first loop iteration\n",
    "                #################### within ####################\n",
    "                # get within-dataset dataframe as just any single test seed and test size \n",
    "                df_within = df_results.groupby(['train_dataset', 'pheno', 'num_train', 'train_seed'], \n",
    "                                               as_index=False).agg({'r_internal':'median',\n",
    "                                                                    'mae_internal':'median',\n",
    "                                                                   'p_mae_gt_internal':'median',\n",
    "                                                                    'q2_internal':'median'})\n",
    "                df_within.to_csv(os.path.join(save_path, 'within',\n",
    "                                              'within_{:s}_{:s}.csv'.format(train_dataset, pheno)),\n",
    "                                 index=False)\n",
    "\n",
    "                #################### within_grouped ####################\n",
    "                # get median within datasets performance\n",
    "                df_within_grouped = df_within.groupby(['train_dataset', 'pheno', 'num_train'],\n",
    "                                  as_index=False).agg(r_med=('r_internal', 'median'),\n",
    "                                                      r_lower=('r_internal', qlower),\n",
    "                                                      r_upper=('r_internal', qupper),\n",
    "                                                     mae_med=('mae_internal', 'median'),\n",
    "                                                     mae_lower=('mae_internal', qlower),\n",
    "                                                     mae_upper=('mae_internal', qupper),\n",
    "                                                     p_mae_gt=('p_mae_gt_internal', 'median'))\n",
    "                df_within_grouped.to_csv(os.path.join(save_path, 'within_grouped',\n",
    "                                              'within_grouped_{:s}_{:s}.csv'.format(train_dataset, pheno)),\n",
    "                                 index=False)\n",
    "\n",
    "            #################### performance_grouped ####################\n",
    "            df_performance_grouped = df_results.groupby(['train_dataset', 'test_dataset', 'pheno', 'num_train', 'num_test'],\n",
    "                                  as_index=False).agg(r_med=('r_external', 'median'),\n",
    "                                                     r_lower=('r_external', qlower),\n",
    "                                                     r_upper=('r_external', qupper),\n",
    "                                                     mae_med=('mae_external', 'median'),\n",
    "                                                     mae_lower=('mae_external', qlower),\n",
    "                                                     mae_upper=('mae_external', qupper),\n",
    "                                                     r_gt=('r_gt', 'min'),\n",
    "                                                      mae_gt=('mae_gt', 'min'),\n",
    "                                                     r_pos_rate=('sig_external', 'mean'),\n",
    "                                                      mae_pos_rate = ('sig_external_mae', 'mean'),\n",
    "                                                     r_sig_ground_truth=('sig_gt', 'mean'),\n",
    "                                                    mae_sig_ground_truth=('sig_gt_mae', 'mean'),\n",
    "                                                     r_ground_truth=('r_gt', 'max'),\n",
    "                                                     mae_ground_truth=('mae_gt', 'max')\n",
    "                                                     )\n",
    "            df_performance_grouped.to_csv(os.path.join(save_path, 'performance_grouped',\n",
    "                                                 'performance_grouped_{:s}_{:s}_{:s}.csv'.format(train_dataset, test_dataset, pheno)),\n",
    "                                    index=False)\n",
    "                \n",
    "            #################### power_grouped ####################\n",
    "            # calculate power as rate of significant results (for significant ground truth results only)\n",
    "            df_power_grouped = df_results.groupby(['train_dataset', 'test_dataset', 'pheno', 'num_train', 'num_test'],\n",
    "                                  as_index=False).agg(r_pos_rate=('sig_external', 'mean'),\n",
    "                                                     r_sig_ground_truth=('sig_gt', 'mean'),\n",
    "                                                     r_ground_truth=('r_gt', 'max'),\n",
    "                                                     mae_pos_rate=('sig_external_mae', 'mean'),\n",
    "                                                     mae_sig_ground_truth=('sig_gt_mae', 'mean'),\n",
    "                                                     mae_ground_truth=('mae_gt', 'max'))   \n",
    "            df_power_grouped.to_csv(os.path.join(save_path, 'power_grouped',\n",
    "                                                 'power_grouped_{:s}_{:s}_{:s}.csv'.format(train_dataset,\n",
    "                                                                                           test_dataset,\n",
    "                                                                                           pheno)),\n",
    "                                    index=False)\n",
    "\n",
    "\n",
    "            #################### effect_size ####################\n",
    "            # calculate median performance\n",
    "            df_effect_size = df_results.groupby(['train_dataset', 'test_dataset', 'pheno', \n",
    "                                                 'num_train', 'num_test', 'sig_external'],\n",
    "                                                as_index=False).agg(r_med=('r_external', 'median'),\n",
    "                                                     r_ground_truth=('r_gt', 'max'),\n",
    "                                                     r_sig_ground_truth=('sig_gt', 'max'),\n",
    "                                                     mae_med=('mae_external', 'median'),\n",
    "                                                     mae_ground_truth=('mae_gt', 'max'),\n",
    "                                                     mae_sig_ground_truth=('sig_gt_mae', 'max'))\n",
    "\n",
    "            # add in column for inflation of effects relative to ground truth\n",
    "            df_effect_size['r_infl_med'] = df_effect_size['r_med'] - df_effect_size['r_ground_truth']  # difference between test and ground truth\n",
    "            df_effect_size['mae_infl_med'] = df_effect_size['mae_med'] - df_effect_size['mae_ground_truth']  # difference between test and ground truth\n",
    "           \n",
    "            # do another one where grouping by MAE significance\n",
    "            df_effect_size_mae = df_results.groupby(['train_dataset', 'test_dataset', 'pheno',\n",
    "                                                 'num_train', 'num_test', 'sig_external_mae'],\n",
    "                                                as_index=False).agg(r_med=('r_external', 'median'),\n",
    "                                                                 r_ground_truth=('r_gt', 'max'),\n",
    "                                                                 r_sig_ground_truth=('sig_gt', 'max'),\n",
    "                                                                 mae_med=('mae_external', 'median'),\n",
    "                                                                 mae_ground_truth=('mae_gt', 'max'),\n",
    "                                                                 mae_sig_ground_truth=('sig_gt_mae', 'max'))\n",
    "            # add in column for inflation of effects relative to ground truth\n",
    "            df_effect_size_mae['mae_infl_med'] = df_effect_size_mae['mae_med'] - df_effect_size_mae['mae_ground_truth']  # difference between test and ground truth\n",
    "            df_effect_size_mae['r_infl_med'] = df_effect_size_mae['r_med'] - df_effect_size_mae['r_ground_truth']  # difference between test and ground truth\n",
    "            \n",
    "            \n",
    "            # combine r and MAE inflation dataframes with new column\n",
    "            df_effect_size['eval_metric'] = 'r'\n",
    "            df_effect_size_mae['eval_metric'] = 'mae'\n",
    "            df_effect_size = pd.concat([df_effect_size, df_effect_size_mae]).reset_index(drop=True)\n",
    "            \n",
    "            df_effect_size.to_csv(os.path.join(save_path, 'effect_size', \n",
    "                                               'effect_size_{:s}_{:s}_{:s}.csv'.format(train_dataset,\n",
    "                                                                                       test_dataset,\n",
    "                                                                                       pheno)),\n",
    "                                  index=False)\n",
    "\n",
    "            \n",
    "            #################### full_test ####################\n",
    "\n",
    "            # calculate difference between internal and external performance\n",
    "            df_results['r_internal_external_diff'] = df_results.r_external - df_results.r_internal\n",
    "            df_results['mae_internal_external_diff'] = df_results.mae_external - df_results.mae_internal            \n",
    "\n",
    "            # take only data at full test sample size\n",
    "            df_full_test = df_results[(df_results.num_test==df_results.ntest_max) & \n",
    "                                    (df_results.test_seed==0)].reset_index(drop=True)\n",
    "            df_full_test.to_csv(os.path.join(save_path, 'full_test', 'full_test_{:s}_{:s}_{:s}.csv'.format(train_dataset, test_dataset, pheno)),\n",
    "                                index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1314fbe",
   "metadata": {},
   "source": [
    "# Combine all processed .csv files into larger files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e7df337",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell aggregates all the saved .csv files\n",
    "'''\n",
    "\n",
    "# loop over possible folder names\n",
    "folder_name_all = [ 'within', 'within_grouped', 'performance_grouped',\n",
    "                   'power_grouped', 'effect_size', 'full_test']\n",
    "for folder_name in folder_name_all:\n",
    "    \n",
    "    # initialize dataframe\n",
    "    df_combined = pd.DataFrame()\n",
    "    \n",
    "    # loop over all possible phenotypes\n",
    "    for pheno in pheno_all:\n",
    "        \n",
    "        # get relevant datasets for each phenotype\n",
    "        if dataset_type!='main':  # for developmental structural connectivity analysis\n",
    "             all_datasets = list(df_sample_size.dataset.unique())\n",
    "        else:  # for main analysis\n",
    "            if (pheno=='mr_scaled') or (pheno=='wm_corrected'):  # no pnc in scaled matrix reasoning or scaled working memory\n",
    "                all_datasets = ['abcd', 'hbn', 'hcpd']\n",
    "            else:\n",
    "                all_datasets = ['abcd', 'hbn', 'hcpd', 'pnc']\n",
    "\n",
    "        # loop over all training datasets\n",
    "        for train_dataset in all_datasets:\n",
    "\n",
    "            # get corresponding test datasets and loop over\n",
    "            if 'within' in folder_name:\n",
    "                all_test_datasets = [np.nan]\n",
    "            elif dataset_type=='data_amount_train':\n",
    "                all_test_datasets = ['hbn', 'hcpd', 'pnc']\n",
    "            elif dataset_type=='data_amount_test':\n",
    "                all_test_datasets = ['abcd_1_scans', 'abcd_2_scans', 'abcd_3_scans', 'abcd_4_scans']\n",
    "            else:\n",
    "                all_test_datasets = [t for t in all_datasets if t!=train_dataset]\n",
    "    \n",
    "            # loop over all test datasets\n",
    "            for within_idx, test_dataset in enumerate(all_test_datasets):\n",
    "                \n",
    "                # do different things whether within-dataset or cross-dataset\n",
    "                if 'within' in folder_name:  # for within-dataset, no consideration of test dataset\n",
    "                    if within_idx==0:  # only need to save one for within-dataset (don't loop over test datasets)\n",
    "                        # load dataframe for combination of .csv type, training dataset, phenotype\n",
    "                        df_tmp = pd.read_csv(os.path.join(save_path,\n",
    "                                                          folder_name,\n",
    "                                                          '{:s}_{:s}_{:s}.csv'.format(folder_name,\n",
    "                                                                                      train_dataset,\n",
    "                                                                                      pheno)))\n",
    "                        # combine dataframes into larger one\n",
    "                        df_combined = pd.concat([df_combined, df_tmp])\n",
    "                else:  # for external validation, consider both training and test dataset\n",
    "                    # load dataframe for combination of .csv type, training dataset, test dataset, phenotype\n",
    "                    df_tmp = pd.read_csv(os.path.join(save_path,\n",
    "                                                      folder_name,\n",
    "                                                      '{:s}_{:s}_{:s}_{:s}.csv'.format(folder_name,\n",
    "                                                                                       train_dataset,\n",
    "                                                                                       test_dataset,\n",
    "                                                                                       pheno)))\n",
    "\n",
    "                    # combine dataframes into larger one\n",
    "                    df_combined = pd.concat([df_combined, df_tmp])\n",
    "                \n",
    "    # save dataframe   \n",
    "    df_combined = df_combined.reset_index(drop=True)\n",
    "    df_combined.to_csv(os.path.join(save_path, folder_name+'.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
